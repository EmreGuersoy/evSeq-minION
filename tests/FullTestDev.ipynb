{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04632f9e-b8db-407f-a2a8-fb7835a6f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from Bio.Data import CodonTable\n",
    "from Bio.Seq import Seq\n",
    "from copy import deepcopy\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b8c728-9295-48b5-9010-b66343504a03",
   "metadata": {},
   "source": [
    "This notebook is for putting together the end-to-end tests of evSeq. We will reconstruct inputs for known outputs, then test them make sure the evSeq software outputs what we expect.\n",
    "\n",
    "Steps:\n",
    "1. Build a random amino acid sequence. This is our reference AA.\n",
    "2. Decide if we are operating in detailed_refseq mode or not. If not, then the random amino acid sequence gives what we expect for the full plate.\n",
    "3. Build variants of the input amino acid sequences. Decide if we have a mixed well or not. A mixed well means we need a second amino acid sequence.\n",
    "4. Build both a \"NNN\" and no variation version of the reference sequence corresponding to positions where we expect mutations.\n",
    "5. Choose a random codon to encode the amino acid changes in the sequence.\n",
    "6. For building reads, choose:\n",
    "    1. Ratio of different sequences. This decides whether or not they are recognized by `variable_thresh`\n",
    "    2. Number of total sequences *at each position*. This decides whether a well is considered dead or not by `variable_count`\n",
    "7. Build a set of perfect reads up to the total number of target sequences. \n",
    "8. Add on bad sequences that should get filtered out by the `bp_q_cutoff`, `length_cutoff`, and `average_q_cutoff` parameters. Also add indels.\n",
    "9. Pad on additional sequence information that creates frameshifts. Add to an input file for processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e930105f-b8e6-444f-a108-c604aabaead2",
   "metadata": {},
   "source": [
    "The BioPython codon table implementation is beyond bad, so we rewrite it here, fixing all of the BioPython flaws:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e03e4ac-d2ac-413d-a41a-c09ae1d6d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCodonTable():\n",
    "    \"\"\"\n",
    "    Because the BioPython implementation of a codon table is all over the place,\n",
    "    fixing all the flaws in this class. Not inheriting because I just don't trust it.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Get the standard codon table from BioPython. Their docs do not say what this is,\n",
    "        # but it looks right from a spot check. As it is, we wrote our own for evSeq, so it\n",
    "        # is good to have a separate codon table used for validation.\n",
    "        bio_codon_table = CodonTable.standard_dna_table\n",
    "        \n",
    "        # Build the forward dictionary. Add the stop codon translations (why\n",
    "        # aren't these included in the first place???).\n",
    "        self.codon_to_aa = bio_codon_table.forward_table.copy()\n",
    "        for stop_codon in bio_codon_table.stop_codons:\n",
    "            self.codon_to_aa[stop_codon] = \"*\"\n",
    "            \n",
    "        # Build the reverse dictionary. BioPython reverse dictionary includes just one \n",
    "        # codon per aa. Fix this.\n",
    "        self.aa_to_codon = {}\n",
    "        for codon, aa in self.codon_to_aa.items():\n",
    "            if aa in self.aa_to_codon:\n",
    "                self.aa_to_codon[aa].append(codon)\n",
    "            else:\n",
    "                self.aa_to_codon[aa] = [codon]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7ea83a-31ae-4f6a-8755-4838f738a79d",
   "metadata": {},
   "source": [
    "We need global variables that define the bounds on our testing. Everything is randomly produced, so we need to set ranges on our sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a245856-42f2-497a-8050-9e8265830bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import evSeq globals needed for testing\n",
    "from evSeq.util.globals import (BARCODE_LENGTH, \n",
    "                                ADAPTER_F,\n",
    "                                ADAPTER_LENGTH_F,\n",
    "                                ADAPTER_R,\n",
    "                                ADAPTER_LENGTH_R)\n",
    "\n",
    "# Reference sequence bounds (IN NUMBER OF AAS!!)\n",
    "MIN_REFSEQ_LEN = 50\n",
    "MAX_REFSEQ_LEN = 251\n",
    "\n",
    "# Bounds on readlength\n",
    "MIN_READLENGTH = 150\n",
    "MAX_READLENGTH = 301\n",
    "assert (MIN_REFSEQ_LEN * 3) <= MIN_READLENGTH\n",
    "\n",
    "# Bounds on quality cutoffs\n",
    "MIN_BP_QUAL_CUTOFF = 15\n",
    "MAX_BP_QUAL_CUTOFF = 36\n",
    "\n",
    "MIN_GLOBAL_QUAL_CUTOFF = 15\n",
    "MAX_GLOBAL_QUAL_CUTOFF = 36\n",
    "\n",
    "MAX_QUAL_ALLOWED = 41\n",
    "\n",
    "# Bounds on sequence length cutoffs\n",
    "MIN_SEQLEN_CUTOFF = 0.0\n",
    "MAX_SEQLEN_CUTOFF = 1.0\n",
    "\n",
    "# Bounds on number of indels added\n",
    "MIN_INDELS_ADDED = 1\n",
    "MAX_INDELS_ADDED = 4\n",
    "\n",
    "# Bounds on primer lengths\n",
    "PRIMER_MIN_LEN = 10\n",
    "PRIMER_MAX_LEN = 41\n",
    "\n",
    "# Bounds on the frameshift for a reference seq\n",
    "FRAMESHIFT_MIN = 0\n",
    "FRAMESHIFT_MAX = 3\n",
    "\n",
    "# Bounds on position identification\n",
    "MIN_VARIABLE_THRESH = 0.0\n",
    "MAX_VARIABLE_THRESH = 1.0\n",
    "MIN_VARIABLE_COUNT = 0\n",
    "MAX_VARIABLE_COUNT = 21\n",
    "\n",
    "# Number of variants in a well\n",
    "MIN_N_VARIANTS = 1\n",
    "MAX_N_VARIANTS = 4\n",
    "\n",
    "# Number of reads in a well\n",
    "MIN_N_READS = 0\n",
    "MAX_N_READS = 101\n",
    "\n",
    "# Bounds on number of mutations per sequence (as a fraction\n",
    "# of the number of amino acids captured by the read-length)\n",
    "MIN_PERC_MUTATED = 0.0\n",
    "MAX_PERC_MUTATED = 0.2\n",
    "\n",
    "# Number of amino acids that can have noise added to them (as\n",
    "# a fraction of the number of amino acids that have been mutated)\n",
    "MIN_NOISE_PERC = 0.0\n",
    "MAX_NOISE_PERC = 0.5\n",
    "\n",
    "# Number of amino acids to rescue in overlapping regions (as\n",
    "# a fraction of the total number of rescue options)\n",
    "RESCUE_FREQ = 0.5\n",
    "\n",
    "# Number of noisy reads added to the fastq\n",
    "MIN_DUD_READS = 0\n",
    "MAX_DUD_READS = 11\n",
    "\n",
    "# Base for quality score calculation\n",
    "Q_SCORE_BASE = 33\n",
    "\n",
    "# Allowed nucleotides\n",
    "ALLOWED_NUCLEOTIDES = (\"A\", \"T\", \"C\", \"G\")\n",
    "\n",
    "# Codon table and allowed amino acid characters\n",
    "CODON_TABLE = CustomCodonTable()\n",
    "ALLOWED_AAS = tuple(sorted(list(CODON_TABLE.aa_to_codon.keys())))\n",
    "INT_TO_AA = dict(enumerate(ALLOWED_AAS))\n",
    "N_AAS = len(ALLOWED_AAS)\n",
    "\n",
    "# Random number generators\n",
    "RANDOM_SEED = sum(ord(char) for char in \"PDawg\")\n",
    "NP_RNG = np.random.default_rng(RANDOM_SEED)\n",
    "RANDOM_RNG = random.Random(RANDOM_SEED)\n",
    "\n",
    "# Barcode file\n",
    "INDEX_DF = pd.read_csv(\"../evSeq/util/index_map.csv\")\n",
    "N_INDICES = len(INDEX_DF)\n",
    "N_PLATES = len(INDEX_DF.IndexPlate.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "743c45d1-f666-4a86-815c-54b90952037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_complement(seq):\n",
    "    return str(Seq(seq).reverse_complement())\n",
    "\n",
    "# Use qualities as an ordinal encoding\n",
    "def ord_to_chr(qualities):\n",
    "    rebased_qs = qualities + Q_SCORE_BASE\n",
    "    return \"\".join(chr(qual) for qual in rebased_qs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01776e8e-6cd9-4c7c-a11e-382fb8f92d5a",
   "metadata": {},
   "source": [
    "We will store basic variables used for building test data in a configuration class, defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8192e0be-4da8-409e-96e6-ea53c56ed522",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QualityGenerator():\n",
    "    \"\"\"\n",
    "    Utility for generating quality score arrays\n",
    "    \"\"\"\n",
    "    def __init__(self, min_q_allowed):\n",
    "        self.min_q_allowed = min_q_allowed\n",
    "        \n",
    "    def generate_qualities(self, size):\n",
    "        return NP_RNG.integers(self.min_q_allowed, MAX_QUAL_ALLOWED,\n",
    "                               size = size)\n",
    "\n",
    "class FakeRefseq():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Randomly create an amino acid reference sequence. Record the length.\n",
    "        self.refseq_len = NP_RNG.integers(MIN_REFSEQ_LEN, MAX_REFSEQ_LEN)\n",
    "        aa_ints = NP_RNG.choice(N_AAS, size = self.refseq_len)\n",
    "        self.aa_refseq = [INT_TO_AA[aa_int] for aa_int in aa_ints]\n",
    "\n",
    "        # Assign a codon to each amino acid.\n",
    "        self.codon_refseq = [RANDOM_RNG.choice(CODON_TABLE.aa_to_codon[aa]) \n",
    "                             for i, aa in enumerate(self.aa_refseq)] \n",
    "        self.codon_refseq_len = self.refseq_len * 3\n",
    "        \n",
    "        # Decide on the frameshift of the reference sequence\n",
    "        self.frameshift_front = NP_RNG.integers(FRAMESHIFT_MIN, FRAMESHIFT_MAX)\n",
    "        self.frameshift_back = NP_RNG.integers(FRAMESHIFT_MIN, FRAMESHIFT_MAX)        \n",
    "        \n",
    "        # Determine the bases for the frameshift\n",
    "        self.frameshift_bp_front = RANDOM_RNG.choices(ALLOWED_NUCLEOTIDES, \n",
    "                                                      k = self.frameshift_front)\n",
    "        self.frameshift_bp_back = RANDOM_RNG.choices(ALLOWED_NUCLEOTIDES, \n",
    "                                                     k = self.frameshift_back)\n",
    "                \n",
    "        # Create primer seeds\n",
    "        self.primer_seed_len_f = NP_RNG.integers(PRIMER_MIN_LEN, PRIMER_MAX_LEN)\n",
    "        self.primer_seed_len_r = NP_RNG.integers(PRIMER_MIN_LEN, PRIMER_MAX_LEN)\n",
    "        self.primer_seed_f = RANDOM_RNG.choices(ALLOWED_NUCLEOTIDES, k = self.primer_seed_len_f)\n",
    "        self.primer_seed_r = RANDOM_RNG.choices(ALLOWED_NUCLEOTIDES, k = self.primer_seed_len_r)\n",
    "        \n",
    "        # Assign the total readable window\n",
    "        self.readable_window_len = (self.codon_refseq_len + \n",
    "                                    self.frameshift_front +\n",
    "                                    self.frameshift_back + \n",
    "                                    self.primer_seed_len_f + \n",
    "                                    self.primer_seed_len_r +\n",
    "                                    ADAPTER_LENGTH_F +\n",
    "                                    ADAPTER_LENGTH_R +\n",
    "                                    2 * BARCODE_LENGTH)\n",
    "    \n",
    "    def define_refseq_windows(self, readlength):\n",
    "        \"\"\"\n",
    "        Defines the region within the mutable refseq region that can be modified.\n",
    "        \"\"\"\n",
    "        # Choose legal positions for making mutations. For forward, the first readable comes after\n",
    "        # the barcode, adapter, and seed region; this is the last readable for reverse. For forward,\n",
    "        # the last readable is the last amino acid  captured in full by the readlength, considering\n",
    "        # the primer binding region, the adapter machinery, and the barcode.\n",
    "        effective_readlength = readlength - BARCODE_LENGTH\n",
    "        max_readable_aa_ind_f = (effective_readlength - self.frameshift_front -\n",
    "                                 ADAPTER_LENGTH_F - self.primer_seed_len_f) // 3\n",
    "        min_readable_aa_ind_r = int(np.ceil((effective_readlength - self.frameshift_back - \n",
    "                                             ADAPTER_LENGTH_R - self.primer_seed_len_r) / 3))\n",
    "        \n",
    "        # Make sure we don't break the bounds of the readable region\n",
    "        max_readable_aa_ind_f = min(max_readable_aa_ind_f, self.refseq_len)\n",
    "        min_readable_aa_ind_r = max(self.refseq_len - min_readable_aa_ind_r, 0)\n",
    "        \n",
    "        # Define the readable positions\n",
    "        self.forward_readable_aas = list(range(0, max_readable_aa_ind_f))\n",
    "        self.reverse_readable_aas = list(range(min_readable_aa_ind_r, self.refseq_len))\n",
    "        mutable_aa_inds = self.forward_readable_aas + self.reverse_readable_aas\n",
    "                \n",
    "        # Get only unique mutable inds\n",
    "        mutable_aa_set = set(mutable_aa_inds)\n",
    "        self.mutable_aa_inds = np.array(list(mutable_aa_set), dtype = int)\n",
    "        self.mutable_aa_inds.sort()\n",
    "        \n",
    "        # Checks on the mutable inds\n",
    "        all_possible_inds = set(range(self.refseq_len))\n",
    "        assert mutable_aa_set.issubset(all_possible_inds)\n",
    "        \n",
    "        # Get the set of indices that is captured by both the forward and reverse reads\n",
    "        self.double_count_inds = set(self.forward_readable_aas) & set(self.reverse_readable_aas)\n",
    "        \n",
    "    def assign_qualities(self, min_q_allowed):\n",
    "        \"\"\"\n",
    "        Assigns base quality scores to all sequence components. This includes:\n",
    "        1. Primer seeds\n",
    "        2. Frameshifts\n",
    "        3. The codon refseq\n",
    "        \"\"\"\n",
    "        # Create a quality generator\n",
    "        q_generator = QualityGenerator(min_q_allowed)\n",
    "        \n",
    "        # Primer seed qualities\n",
    "        self.primer_qualities_f = q_generator.generate_qualities(self.primer_seed_len_f)\n",
    "        self.primer_qualities_r = q_generator.generate_qualities(self.primer_seed_len_r)\n",
    "        \n",
    "        # Barcode qualities\n",
    "        self.fbc_qualities = q_generator.generate_qualities(BARCODE_LENGTH)\n",
    "        self.rbc_qualities = q_generator.generate_qualities(BARCODE_LENGTH)\n",
    "        \n",
    "        # Adapter qualities\n",
    "        self.adapter_qualities_f = q_generator.generate_qualities(ADAPTER_LENGTH_F)\n",
    "        self.adapter_qualities_r = q_generator.generate_qualities(ADAPTER_LENGTH_R)\n",
    "        \n",
    "        # Frameshift qualities\n",
    "        self.frameshift_front_qualities = q_generator.generate_qualities(self.frameshift_front)\n",
    "        self.frameshift_back_qualities = q_generator.generate_qualities(self.frameshift_back)\n",
    "        \n",
    "        # Variable region base qualities\n",
    "        self.base_variable_qualities = q_generator.generate_qualities(self.codon_refseq_len)\n",
    "        \n",
    "    @staticmethod\n",
    "    def aa_seq_to_codon_seq(aa_seq):\n",
    "        return [RANDOM_RNG.choice(CODON_TABLE.aa_to_codon[aa]) \n",
    "                for i, aa in enumerate(aa_seq)]         \n",
    "        \n",
    "    @property\n",
    "    def refseq_bp_seq(self):\n",
    "        \"\"\"\n",
    "        Returns the sequence of the refseq that will be fed into evSeq\n",
    "        \"\"\"\n",
    "        return \"\".join(\n",
    "            self.primer_seed_f +\n",
    "            self.frameshift_bp_front +\n",
    "            self.codon_refseq +\n",
    "            self.frameshift_bp_back +\n",
    "            self.primer_seed_r\n",
    "        )\n",
    "\n",
    "        \n",
    "# Class that holds parameters that will be needed by evSeq\n",
    "class Config():\n",
    "    def __init__(self, detailed = True):\n",
    "        \"\"\"\n",
    "        Builds a set of conditions that might be passed into an evSeq run.\n",
    "        \"\"\"\n",
    "        # Record whether or not this is a detailed run\n",
    "        self.detailed = detailed\n",
    "        \n",
    "        # Build as many reference sequences as needed\n",
    "        n_refs_needed = N_INDICES if detailed else N_PLATES\n",
    "        self.refseqs = [FakeRefseq() for _ in range(n_refs_needed)] \n",
    "        \n",
    "        # Decide on the readlength that we will be using. The maximum allowed\n",
    "        # readlength cannot be longer than the full sequencable length of\n",
    "        # the shortest a reference sequence\n",
    "        min_refseq_len = min(refseq.readable_window_len for refseq in self.refseqs)\n",
    "        max_readlength = min(min_refseq_len, MAX_READLENGTH)\n",
    "        self.readlength = NP_RNG.integers(MIN_READLENGTH, max_readlength)\n",
    "                \n",
    "        # Decide on the input variables that will define the run, including \n",
    "        # average_q_cutoff, bp_q_cutoff, length_cutoff, variable_thresh, and\n",
    "        # variable_count\n",
    "        self.average_q_cutoff = NP_RNG.integers(MIN_GLOBAL_QUAL_CUTOFF, MAX_GLOBAL_QUAL_CUTOFF)\n",
    "        self.bp_q_cutoff = NP_RNG.integers(MIN_BP_QUAL_CUTOFF, MAX_BP_QUAL_CUTOFF)\n",
    "        self.length_cutoff = NP_RNG.uniform(MIN_SEQLEN_CUTOFF, MAX_SEQLEN_CUTOFF)\n",
    "        self.variable_thresh = NP_RNG.uniform(MIN_VARIABLE_THRESH, MAX_VARIABLE_THRESH)\n",
    "        self.variable_count = NP_RNG.integers(MIN_VARIABLE_COUNT, MAX_VARIABLE_COUNT)\n",
    "        \n",
    "        # Build base quality scores for the reference sequences. Also define the allowed\n",
    "        # mutagenesis windows for the amino acids, which encompasses the last amino acids\n",
    "        # captured in full by the readlength. \n",
    "        for refseq in self.refseqs:\n",
    "            refseq.assign_qualities(max(self.average_q_cutoff, self.bp_q_cutoff) + 1)\n",
    "            refseq.define_refseq_windows(self.readlength)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41dcb37-fce2-4f65-b0c9-7908e16c7a1c",
   "metadata": {},
   "source": [
    "The basic data generator is a FakeWell instance. This holds methods for building fake data from the Config object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a981cd0-c862-4412-9bc3-dbabf7346185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class that holds all relevant information for a variant\n",
    "class Variant(FakeData):\n",
    "    def __init__(self, well, counts, minimum_reads_allowed):\n",
    "        \n",
    "        # The well is an instance variables\n",
    "        self.well = well\n",
    "        \n",
    "        # Set the total number of counts for the variant and the\n",
    "        # minimum reads that are allowed for it\n",
    "        self.total_counts = counts\n",
    "        self.minimum_reads_allowed = minimum_reads_allowed\n",
    "        \n",
    "        # Don't move forward if there are no counts\n",
    "        self.no_counts = (counts == 0)\n",
    "        \n",
    "        if not self.no_counts:\n",
    "            \n",
    "            # Choose the variable positions and build variants\n",
    "            self.choose_variable_positions()\n",
    "            self.build_variants()\n",
    "\n",
    "            # Assign Q scores. Get expected counts.\n",
    "            self.incorporate_noisy_positions()\n",
    "        \n",
    "    def choose_variable_positions(self):\n",
    "        \"\"\"\n",
    "        Chooses the variable positions for the variant and assigns mutant\n",
    "        amino acids/codons.\n",
    "        \"\"\"\n",
    "        warnings.warn(\"You need to make sure that the amino acid returned is different\"\n",
    "                      \" from the existing one. Same goes for the nucleotides.\")\n",
    "        # Get the number of mutations to make\n",
    "        n_mutable_positions = len(self.well.refseq.mutable_aa_inds)\n",
    "        min_n_muts = int(MIN_PERC_MUTATED * n_mutable_positions)\n",
    "        max_n_muts = int(MAX_PERC_MUTATED * n_mutable_positions) + 1\n",
    "        self.n_variable_positions = NP_RNG.integers(min_n_muts, max_n_muts)\n",
    "        \n",
    "        # Decide on the positions that will be varied within the variant\n",
    "        # This must be in the readable region. \n",
    "        self.mutated_positions = NP_RNG.choice(self.well.refseq.mutable_aa_inds, \n",
    "                                               size = self.n_variable_positions,\n",
    "                                               replace = False)\n",
    "        self.mutated_positions.sort()\n",
    "        \n",
    "        # Choose variable amino acids\n",
    "        self.variable_aas = RANDOM_RNG.choices(ALLOWED_AAS, k = self.n_variable_positions)\n",
    "        \n",
    "        # Choose a random codon for encoding said amino acids. It cannot be the\n",
    "        # same as the existing codon.\n",
    "        self.variable_codons = [None] * self.n_variable_positions\n",
    "        for i, aa in enumerate(self.variable_aas):\n",
    "            \n",
    "            # Get the options for the alternate codons. Again, we cannot\n",
    "            # reuse the codon that is already present in the refseq\n",
    "            existing_codon = self.well.refseq.codon_refseq[self.mutated_positions[i]]\n",
    "            codon_opts = [codon for codon in CODON_TABLE.aa_to_codon[aa]\n",
    "                          if codon != existing_codon]\n",
    "            \n",
    "            # If there are no alternate codons (e.g., if we selected methionine as\n",
    "            # our mutant aa and refseq was already methionine), then just sample from\n",
    "            # leucine\n",
    "            if len(codon_opts) == 0:\n",
    "                self.variable_aas[i] = \"L\"\n",
    "                codon_opts = CODON_TABLE.aa_to_codon[\"L\"]\n",
    "                \n",
    "            # Select the new codon\n",
    "            self.variable_codons[i] = RANDOM_RNG.choice(codon_opts)\n",
    "            \n",
    "    def build_variants(self):\n",
    "        \"\"\"\n",
    "        Builds sequence variants based on the refseq sequence and chosen replacement\n",
    "        amino acids/positions\n",
    "        \"\"\"\n",
    "        # Create base mutant sequences based on the refseq\n",
    "        self.base_mut_aa_seq = self.well.refseq.aa_refseq.copy()\n",
    "        base_mut_codon_seq = self.well.refseq.codon_refseq.copy()\n",
    "\n",
    "        # Loop over the mutated positions and add to the base sequence\n",
    "        assert len(self.mutated_positions) == len(self.variable_aas)\n",
    "        assert len(self.mutated_positions) == len(self.variable_codons)\n",
    "        for i, mutated_pos in enumerate(self.mutated_positions):\n",
    "            self.base_mut_aa_seq[mutated_pos] = self.variable_aas[i]\n",
    "            base_mut_codon_seq[mutated_pos] = self.variable_codons[i]\n",
    "\n",
    "        # Create forward and reverse copies of the codon sequences. Make as many copies\n",
    "        # as there are variants for the refseq\n",
    "        self.mut_codon_seqs_f = [base_mut_codon_seq.copy() for _ in range(self.total_counts)]\n",
    "        self.mut_codon_seqs_r = deepcopy(self.mut_codon_seqs_f)\n",
    "        \n",
    "    def id_noisy_positions(self):\n",
    "        \"\"\"\n",
    "        Adds noise to a number of mutated positions.\n",
    "        \"\"\"\n",
    "        # Decide how many reads for combos of amino acids will have noise\n",
    "        # added to them. This number must fall above the minimum counts required.\n",
    "        buffer_region = self.total_counts - self.minimum_reads_allowed\n",
    "        n_combos_destroyed = NP_RNG.integers(buffer_region) if buffer_region > 0 else 0\n",
    "\n",
    "        # Get the expected number of both bp and aa combinations\n",
    "        self.expected_combo_counts = self.total_counts - n_combos_destroyed \n",
    "\n",
    "        # Decide which reads will have noise added.\n",
    "        read_inds = np.arange(self.total_counts)\n",
    "        noisy_reads = NP_RNG.choice(read_inds, \n",
    "                                    size = n_combos_destroyed,\n",
    "                                    replace = False)\n",
    "        noisy_reads.sort()\n",
    "\n",
    "        # Determine options for noisy positions.\n",
    "        if len(self.well.refseq.double_count_inds) != 0:\n",
    "            forbidden_noisy_aas = {min(self.well.refseq.double_count_inds), \n",
    "                                   max(self.well.refseq.double_count_inds)}\n",
    "        else:\n",
    "            forbidden_noisy_aas = set()\n",
    "        noisened_position_options = np.array([pos for pos in self.mutated_positions\n",
    "                                              if pos not in forbidden_noisy_aas])\n",
    "\n",
    "        # Determine how many noisy positions per read. \n",
    "        n_noisey_per_read = int(len(noisened_position_options) * \n",
    "                                NP_RNG.uniform(MIN_NOISE_PERC, MAX_NOISE_PERC))\n",
    "\n",
    "        # Decide which amino acids within each read will have noise added.\n",
    "        # Do not add noise to codons within 1 of the double overlap region.\n",
    "        noisy_positions = np.array([NP_RNG.choice(noisened_position_options, \n",
    "                                                  size = n_noisey_per_read,\n",
    "                                                  replace = False)\n",
    "                                    for _ in range(n_combos_destroyed)])\n",
    "\n",
    "        # Determine which bases are noisy for each noisy amino acid. \n",
    "        n_noisy_bases_by_noisy_pos = NP_RNG.integers(1, 4, size = (n_combos_destroyed, n_noisey_per_read))\n",
    "        noisy_bases_by_noisy_pos = [[NP_RNG.choice(3,\n",
    "                                                  size = n_noisy_bases,\n",
    "                                                  replace = False) \n",
    "                                     for n_noisy_bases in noisy_base_array]\n",
    "                                    for noisy_base_array in n_noisy_bases_by_noisy_pos]\n",
    "        \n",
    "        # Checks\n",
    "        assert len(noisy_reads) == len(noisy_positions)\n",
    "        \n",
    "        return noisy_reads, noisy_positions, noisy_bases_by_noisy_pos\n",
    "                            \n",
    "    def build_expected_count_arrays(self):\n",
    "\n",
    "        # Create arrays of counts.\n",
    "        expected_aa_counts = np.full(self.well.refseq.refseq_len, \n",
    "                                     self.total_counts)\n",
    "        expected_bp_counts = np.full(self.well.refseq.codon_refseq_len, \n",
    "                                     self.total_counts)\n",
    "\n",
    "        # Double positions in the counts where we have overlap \n",
    "        for i, mutant_pos in enumerate(self.mutated_positions):\n",
    "            if mutant_pos in self.well.refseq.double_count_inds:\n",
    "\n",
    "                # Double aa counts\n",
    "                expected_aa_counts[i] *= 2\n",
    "\n",
    "                # Double bp counts\n",
    "                bp_start_ind = i * 3\n",
    "                for bp_ind in range(bp_start_ind, bp_start_ind + 3):\n",
    "                    expected_bp_counts[bp_ind] *= 2\n",
    "\n",
    "        return expected_aa_counts, expected_bp_counts\n",
    "        \n",
    "    def incorporate_noisy_positions(self):\n",
    "        \"\"\"\n",
    "        Assigns counts to different bases and amino acids, then assigns quality scores\n",
    "        to get them to these counts\n",
    "        \"\"\"\n",
    "        # Identify noisy reads, positions, and nucleotides\n",
    "        noisy_reads, noisy_positions, noisy_bases_by_noisy_pos = self.id_noisy_positions()\n",
    "\n",
    "        # Build expected output counts for amino acids and bases\n",
    "        self.expected_aa_counts, self.expected_bp_counts = self.build_expected_count_arrays()\n",
    "        \n",
    "        # Create two quality score arrays. One is for the forward read and the other\n",
    "        # is for the reverse reads\n",
    "        self.f_quals = np.tile(self.well.refseq.base_variable_qualities.copy(),\n",
    "                          (self.total_counts, 1))\n",
    "        self.r_quals = self.f_quals.copy()\n",
    "        min_existing_q = self.f_quals.min()\n",
    "        bad_qual_q = min_existing_q - 2\n",
    "\n",
    "        # Add noise to positions. Adjust counts and qualities accordingly.\n",
    "        for noisy_read, noisy_position_array, noisy_bp_array in \\\n",
    "            zip(noisy_reads, noisy_positions, noisy_bases_by_noisy_pos):\n",
    "\n",
    "            # Loop over all positions and adjust basepair quality as appropriate\n",
    "            for noisy_pos, noisy_base_set in zip(noisy_position_array, noisy_bp_array):\n",
    "\n",
    "                # Determine count adjustment for the position\n",
    "                double_count_pos = (noisy_pos in self.well.refseq.double_count_inds)\n",
    "                count_adj = 2 if double_count_pos else 1\n",
    "\n",
    "                # If a position is in the double-read region, with some probability\n",
    "                # one read will rescue the other. If we rescue, then we set only 1 \n",
    "                # codon/amino acid as low quality. The other one is kept fine. We also\n",
    "                # mutate the low-quality codon again (this should never be counted, providing\n",
    "                # a test to make sure that we are appropriately ignoring codons)\n",
    "                rescue_check = (double_count_pos and (NP_RNG.uniform() < RESCUE_FREQ))\n",
    "                rescue = True if rescue_check else False\n",
    "\n",
    "                # Get the base index for the noisy position\n",
    "                noisy_base_index_zero = noisy_pos * 3\n",
    "\n",
    "                # Loop over the base set and add noise\n",
    "                for noisy_base in noisy_base_set:\n",
    "\n",
    "                    # Calculate the actual index\n",
    "                    actual_base_ind = noisy_base_index_zero + noisy_base\n",
    "\n",
    "                    # If rescuing, choose one of the quality score arrays to update. Also add \n",
    "                    # an error to the low-quality sequence. This should be ignored the evSeq software.\n",
    "                    if rescue:\n",
    "\n",
    "                        # Define options for qualities and sequences\n",
    "                        qual_opts = [self.f_quals, self.r_quals]\n",
    "                        codon_opts = [self.mut_codon_seqs_f, self.mut_codon_seqs_r]\n",
    "\n",
    "                        # Choose which quality and sequence array will be update\n",
    "                        target_ind = 0 if NP_RNG.uniform() < 0.5 else 1\n",
    "                        target_qual_array = qual_opts[target_ind]\n",
    "                        target_codon_list = codon_opts[target_ind]\n",
    "\n",
    "                        # Update the qualities in the chosen array\n",
    "                        target_qual_array[noisy_read, actual_base_ind] = bad_qual_q\n",
    "\n",
    "                        # Choose a replacement base\n",
    "                        replacement_codon = list(target_codon_list[noisy_read][noisy_pos])\n",
    "                        replacement_codon[noisy_base] = RANDOM_RNG.choice(ALLOWED_NUCLEOTIDES)\n",
    "                        target_codon_list[noisy_read][noisy_pos] = \"\".join(replacement_codon)\n",
    "\n",
    "                        # Set the count adjuster. It is only 1 here, because we lost a base.\n",
    "                        count_adj = 1\n",
    "\n",
    "                    # Otherwise, we adjust both quality arrays and make no changes to sequence\n",
    "                    else:\n",
    "\n",
    "                        # Set quality to be 2 less than the minimum existing quality in\n",
    "                        # the array of q-scores.\n",
    "                        self.f_quals[noisy_read, actual_base_ind] = bad_qual_q\n",
    "                        self.r_quals[noisy_read, actual_base_ind] = bad_qual_q\n",
    "\n",
    "                    # Adjust the counts. \n",
    "                    self.expected_aa_counts[noisy_pos] -= count_adj\n",
    "                    self.expected_bp_counts[actual_base_ind] -= count_adj\n",
    "        \n",
    "    def build_perfect_reads(self):\n",
    "        \"\"\"\n",
    "        Assigns a `perfect_reads` variable to the instance.\n",
    "        \"\"\"\n",
    "        # Confirm that we have as many qualities as mutant sequences\n",
    "        assert len(self.f_quals) == self.total_counts\n",
    "        assert len(self.f_quals) == len(self.r_quals)\n",
    "        assert len(self.f_quals) == len(self.mut_codon_seqs_f)\n",
    "        assert len(self.f_quals) == len(self.mut_codon_seqs_r)\n",
    "\n",
    "        # Now loop over the remaining sequence variants and build entries.\n",
    "        fastq_r1 = [None] * self.total_counts\n",
    "        fastq_r2 = fastq_r1.copy()\n",
    "        for i in range(self.total_counts):\n",
    "\n",
    "            # Confirm that mutant sequence length matches with quality score length\n",
    "            full_forward_bp = \"\".join(self.mut_codon_seqs_f[i])\n",
    "            full_forward_q = self.f_quals[i]\n",
    "            assert len(full_forward_bp) == len(full_forward_q)\n",
    "\n",
    "            full_rev_bp = \"\".join(self.mut_codon_seqs_r[i])\n",
    "            full_rev_q = self.r_quals[i]\n",
    "            assert len(full_rev_bp) == len(full_rev_q)\n",
    "            \n",
    "            assert len(full_forward_bp) == len(full_rev_bp)    \n",
    "            \n",
    "            # Record fastq entries\n",
    "            fastq_r1[i], fastq_r2[i] = self.well.build_fastq_entry(full_forward_bp,\n",
    "                                                                   full_rev_bp,\n",
    "                                                                   full_forward_q,\n",
    "                                                                   full_rev_q,\n",
    "                                                                   i)\n",
    "\n",
    "        return fastq_r1, fastq_r2        \n",
    "    \n",
    "    def build_output_counts(self):\n",
    "        \"\"\"\n",
    "        Builds output files for the different `OutputCounts`\n",
    "        \"\"\"\n",
    "        pass  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "160d02c5-df88-4ba2-95a8-13670eb84b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that holds information for a test well\n",
    "class FakeWell(FakeData):\n",
    "    def __init__(self, config, reference_sequence):\n",
    "    \n",
    "        # Assign the config and reference sequence objects as instance variables\n",
    "        self.config = config\n",
    "        self.refseq = reference_sequence\n",
    "        \n",
    "        # Create plate, well, and barcode variables as a placeholder.\n",
    "        # This will be filled when the well is passed with others to\n",
    "        # a FakeRun instance.\n",
    "        self.platename = None\n",
    "        self.wellname = None\n",
    "        self.f_barcode = None\n",
    "        self.r_barcode = None\n",
    "                \n",
    "        # Get the total number of reads in the well. \n",
    "        self.total_reads = NP_RNG.integers(MIN_N_READS, MAX_N_READS)\n",
    "        \n",
    "        # Decide on how many variants we want in the well. \n",
    "        self.assign_n_variants()\n",
    "        \n",
    "        # Decide the relative abundance of each variant, then build variants\n",
    "        abundances = self.calculate_variant_abundances()\n",
    "        \n",
    "        # Only continue if there are any variants\n",
    "        if abundances is None:\n",
    "            self.dud_well = True\n",
    "        else:\n",
    "            self.dud_well = False\n",
    "            variant_abundances, minimum_reads_per_variant = abundances\n",
    "            self.variants = [Variant(self, abundance, minimum_reads_per_variant) for\n",
    "                             abundance in variant_abundances]\n",
    "         \n",
    "        warnings.warn(\"Add `murder` to list of functions\")\n",
    "    \n",
    "    def assign_n_variants(self):\n",
    "        \"\"\"\n",
    "        Determines how many variants are in the well.\n",
    "        \"\"\"\n",
    "        # Decide on how many variants we want in the well. The maximum allowed is\n",
    "        # the minimum of (1) how many variants we can spread reads over to get above\n",
    "        # the `variable_count` threshold, (2) the most allowed with the given \n",
    "        # `variable_thresh`, and (3) the `MAX_N_VARIANTS` global.\n",
    "        count_divisor = 1 if self.config.variable_count == 0 else self.config.variable_count\n",
    "        max_n_variants = min(\n",
    "            self.total_reads // count_divisor,\n",
    "            int(1 // self.config.variable_thresh) - 1,\n",
    "            MAX_N_VARIANTS\n",
    "        )\n",
    "        \n",
    "        # Make it so that we always have at least one variant\n",
    "        if max_n_variants == 0:\n",
    "            max_n_variants = 1\n",
    "        self.n_variants = NP_RNG.integers(MIN_N_VARIANTS, max_n_variants + 1)\n",
    "    \n",
    "    def calculate_variant_abundances(self):\n",
    "        \"\"\"\n",
    "        Decide how many counts go to each variant.\n",
    "        \"\"\"\n",
    "        # Each variant must be more abundant than both the variable threshold\n",
    "        # and the variable counts\n",
    "        minimum_reads_per_variant = max(\n",
    "            int(np.ceil(self.config.variable_thresh * self.total_reads)),\n",
    "            self.config.variable_count\n",
    "        )\n",
    "        \n",
    "        # If we cannot get reads for all variants, this is a dud well\n",
    "        if minimum_reads_per_variant * self.n_variants > self.total_reads:\n",
    "            return None\n",
    "        \n",
    "        # Now assign read counts to each variant. If there is only 1 variant, then it gets\n",
    "        # all reads\n",
    "        if self.n_variants == 1:\n",
    "            variant_counts = [self.total_reads]\n",
    "\n",
    "        # If there are more than 1 variants, for each variant, we sample\n",
    "        # from the range of minimum reads per variant to total reads \n",
    "        # remaining, considering that some reads have already been\n",
    "        # assigned to variants\n",
    "        else:\n",
    "            total_reads_available = self.total_reads\n",
    "            variants_remaining = self.n_variants\n",
    "            variant_counts = [None] * self.n_variants\n",
    "            for i in range(self.n_variants):\n",
    "\n",
    "                # Get the maximum number of reads that we can sample\n",
    "                max_reads_available_ind = FakeWell.calculate_maximum_reads_ind(total_reads_available, \n",
    "                                                                               variants_remaining,\n",
    "                                                                               minimum_reads_per_variant)\n",
    "\n",
    "                # Sample to get the number of variants\n",
    "                if minimum_reads_per_variant == max_reads_available_ind:\n",
    "                    sampled_variants = minimum_reads_per_variant\n",
    "                else:\n",
    "                    sampled_variants = NP_RNG.integers(minimum_reads_per_variant, max_reads_available_ind)\n",
    "                variant_counts[i] = sampled_variants\n",
    "\n",
    "                # Update the number of reads available for sampling and the number of variants\n",
    "                # still needing samples\n",
    "                total_reads_available -= sampled_variants\n",
    "                assert total_reads_available > 0\n",
    "                variants_remaining -= 1\n",
    "\n",
    "                # If this is the breakpoint, assign the remaining reads to the remaining variant\n",
    "                if variants_remaining == 1:\n",
    "                    variant_counts[-1] = total_reads_available\n",
    "                    break\n",
    "\n",
    "        # Checks to make sure the counts were assigned appropriately\n",
    "        assert not any(count is None for count in variant_counts)\n",
    "        assert sum(variant_counts) == self.total_reads   \n",
    "        \n",
    "        return variant_counts, minimum_reads_per_variant\n",
    "    \n",
    "    def build_corrupted_reads(self):\n",
    "        \"\"\"\n",
    "        Assigns `corrupted_reads` and `corrupted_bases` variables to the instance.\n",
    "        \"\"\"\n",
    "        # Choose how many sequences to add of each flavor.\n",
    "        corruption_levels = NP_RNG.integers(MIN_DUD_READS,\n",
    "                                            MAX_DUD_READS,\n",
    "                                            size = 3)\n",
    "        \n",
    "        # Add reads with indels. \n",
    "        indel_reads = self.build_indel_reads(corruption_levels[0])\n",
    "        \n",
    "        # Add sequences filtered out by the average_q_cutoff. \n",
    "        low_q_reads = self.build_low_q_reads(corruption_levels[1])\n",
    "        \n",
    "        # Add sequences filtered out by the length_cutoff. This is added to `corrupted_reads`.\n",
    "        short_reads = self.build_short_reads(corruption_levels[2])\n",
    "        \n",
    "        return indel_reads, low_q_reads, short_reads\n",
    "        \n",
    "    def build_indel_reads(self, n_indels):\n",
    "        \n",
    "        # Choose how many sequences to add of each flavor.\n",
    "        corruption_levels = NP_RNG.integers(MIN_DUD_READS,\n",
    "                                            MAX_DUD_READS,\n",
    "                                            size = 3)\n",
    "\n",
    "        # Get the base sequences and qualities\n",
    "        f_indel_reads = [list(self.base_refseq) for _ in range(n_indels)]\n",
    "        f_indel_qs = [self.refseq.base_variable_qualities.copy() for _ in range(n_indels)]\n",
    "        r_indel_reads = [list(self.base_refseq) for _ in range(n_indels)]\n",
    "        r_indel_qs = [self.refseq.base_variable_qualities.copy() for _ in range(n_indels)]\n",
    "\n",
    "        # Create lists for storing fastq entries\n",
    "        r1s = [None] * n_indels\n",
    "        r2s = [None] * n_indels\n",
    "        target_f_read = [True, False]\n",
    "\n",
    "        # Add indels. \n",
    "        for read_target in target_f_read:\n",
    "\n",
    "            # Set targets\n",
    "            if read_target:\n",
    "                fastq_list = r1s\n",
    "                mutable_positions = self.refseq.forward_readable_aas\n",
    "                indel_reads = f_indel_reads\n",
    "                indel_qs = f_indel_qs\n",
    "            else:\n",
    "                fastq_list = r2s\n",
    "                mutable_positions = self.refseq.reverse_readable_aas\n",
    "                indel_reads = r_indel_reads\n",
    "                indel_qs = r_indel_qs\n",
    "\n",
    "            # Add indels\n",
    "            for i in range(n_indels):\n",
    "\n",
    "                # Decide if adding an insertions or deletions and the number\n",
    "                # to add\n",
    "                insertion = True if 0.5 < NP_RNG.uniform() else False\n",
    "                n_muts = NP_RNG.integers(MIN_INDELS_ADDED, MAX_INDELS_ADDED)\n",
    "\n",
    "                # Decide on locations of indels\n",
    "                indel_aa_locs = NP_RNG.choice(mutable_positions,\n",
    "                                              size = n_muts,\n",
    "                                              replace = False)\n",
    "                indel_codon_locs = NP_RNG.integers(0, 3, size = n_muts)\n",
    "                indel_locs = indel_aa_locs * 3 + indel_codon_locs\n",
    "                indel_locs = np.sort(indel_locs)[::-1] # So that largest indices are removed first\n",
    "                \n",
    "                # Add indels to sequences\n",
    "                for indel_loc in indel_locs:\n",
    "\n",
    "                    # If insertion, add a random character\n",
    "                    if insertion:\n",
    "                        indel_reads[i].insert(indel_loc, RANDOM_RNG.choice(ALLOWED_NUCLEOTIDES))\n",
    "                    else:\n",
    "                        del(indel_reads[i][indel_loc])\n",
    "\n",
    "                # Add indels to qualities\n",
    "                if insertion:\n",
    "                    new_qs = NP_RNG.integers(self.config.bp_q_cutoff, MAX_QUAL_ALLOWED, size = n_muts)\n",
    "                    indel_qs[i] = np.concatenate((indel_qs[i], new_qs))\n",
    "                else:\n",
    "                    indel_qs[i] = indel_qs[i][:-n_muts]\n",
    "\n",
    "                # Convert reads to strings\n",
    "                indel_reads[i] = \"\".join(indel_reads[i])\n",
    "\n",
    "        # Store results\n",
    "        for i in range(n_indels):\n",
    "            r1s[i], r2s[i] = self.build_fastq_entry(f_indel_reads[i],\n",
    "                                                    r_indel_reads[i],\n",
    "                                                    f_indel_qs[i],\n",
    "                                                    r_indel_qs[i],\n",
    "                                                    i)\n",
    "        \n",
    "        return r1s, r2s        \n",
    "        \n",
    "    def build_low_q_reads(self, n_low_q):\n",
    "        \n",
    "        # Create as many copies of the reference sequence as we want bad sequences\n",
    "        bad_seq_copies = [self.base_refseq] * n_low_q\n",
    "        bad_seq_quals = NP_RNG.integers(0, self.config.average_q_cutoff,\n",
    "                                        size = (n_low_q, len(self.base_refseq)))\n",
    "\n",
    "        # Build the fastq entries\n",
    "        forward_bad_q = [None] * n_low_q\n",
    "        reverse_bad_q = [None] * n_low_q\n",
    "        for i, (bad_seq_copy, bad_seq_qual) in enumerate(zip(bad_seq_copies, bad_seq_quals)):\n",
    "            forward_bad_q[i], reverse_bad_q[i] = self.build_fastq_entry(bad_seq_copy,\n",
    "                                                                        bad_seq_copy,\n",
    "                                                                        bad_seq_qual,\n",
    "                                                                        bad_seq_qual,\n",
    "                                                                        i)\n",
    "            \n",
    "        return forward_bad_q, reverse_bad_q\n",
    "    \n",
    "    def build_short_reads(self, n_short):\n",
    "\n",
    "        # Identify the longest possible short read\n",
    "        max_allowed_length = int(self.config.length_cutoff * self.config.readlength)\n",
    "        \n",
    "        # Determine the maximum allowed readable window that gives the longest\n",
    "        # possible short read\n",
    "        forward_readable_max = (max_allowed_length - \n",
    "                                self.refseq.frameshift_front - \n",
    "                                self.refseq.primer_seed_len_f -\n",
    "                                ADAPTER_LENGTH_F - BARCODE_LENGTH)\n",
    "        reverse_readable_max = (max_allowed_length -\n",
    "                                self.refseq.frameshift_back -\n",
    "                                self.refseq.primer_seed_len_r -\n",
    "                                ADAPTER_LENGTH_R - BARCODE_LENGTH)\n",
    "        \n",
    "        # If we cannot add short reads, just return empty lists\n",
    "        if forward_readable_max <= 0 or reverse_readable_max <= 0:\n",
    "            return ([], [])\n",
    "        \n",
    "        # Sample the lengths of the bad fragments\n",
    "        bad_fragment_lengths_f = NP_RNG.integers(0, forward_readable_max, \n",
    "                                                 size = n_short)\n",
    "        bad_fragment_lengths_r = NP_RNG.integers(0, reverse_readable_max, \n",
    "                                                 size = n_short)\n",
    "\n",
    "        # Build the fragments\n",
    "        r1 = [None] * n_short\n",
    "        r2 = [None] * n_short\n",
    "        for i, (frag_len_f, frag_len_r) in enumerate(zip(bad_fragment_lengths_f, bad_fragment_lengths_r)):\n",
    "\n",
    "            # Slice the base reference sequence and the base qualities\n",
    "            min_r = self.refseq.codon_refseq_len - frag_len_r\n",
    "            newseq_f = self.base_refseq[:frag_len_f]\n",
    "            newseq_r = self.base_refseq[min_r:]\n",
    "        \n",
    "            newq_f = self.refseq.base_variable_qualities[:frag_len_f]\n",
    "            newq_r = self.refseq.base_variable_qualities[min_r:]\n",
    "\n",
    "            # Create entries\n",
    "            r1[i], r2[i] = self.build_fastq_entry(newseq_f, newseq_r,\n",
    "                                                  newq_f, newq_r, i)\n",
    "            \n",
    "        return r1, r2  \n",
    "            \n",
    "    # Build a fastq entry\n",
    "    def build_fastq_entry(self,\n",
    "                          full_forward_bp,\n",
    "                          full_rev_bp,\n",
    "                          full_forward_q, \n",
    "                          full_rev_q, \n",
    "                          i):\n",
    "        \"\"\"\n",
    "        Sequences and qs should be in the order we expect to see them in the fastq (e.g,\n",
    "        the reverse complement should be taken of the forward seq before going into\n",
    "        this function)\n",
    "        \"\"\"\n",
    "        # Get the start sequences and qualities\n",
    "        start_f_seq, start_f_q = self.build_start_seq_f()\n",
    "        start_r_seq, start_r_q = self.build_start_seq_r()\n",
    "        \n",
    "        # Build the start sequences for the forward and reverse reads.\n",
    "        # We need the reverse complement of the reverse primer\n",
    "        available_read_f = self.config.readlength - len(start_f_seq)\n",
    "        available_read_r = self.config.readlength - len(start_r_seq)\n",
    "        \n",
    "        # Get the forward and reverse readable sequences\n",
    "        forward_readable = full_forward_bp[:available_read_f]\n",
    "        reverse_readable = reverse_complement(full_rev_bp)[:available_read_r]\n",
    "\n",
    "        # Get the forward and reverse readable qualities\n",
    "        forward_qs = ord_to_chr(full_forward_q[:available_read_f])\n",
    "        reverse_qs = ord_to_chr(np.flip(full_rev_q)[:available_read_r])\n",
    "                \n",
    "        # Complete the forward and reverse sequences\n",
    "        complete_f_seq = start_f_seq + forward_readable\n",
    "        complete_r_seq = start_r_seq + reverse_readable\n",
    "        complete_f_qual = start_f_q + forward_qs\n",
    "        complete_r_qual = start_r_q + reverse_qs\n",
    "\n",
    "        # Record fastq entries\n",
    "        r1 = f\"Test{i}\\n{complete_f_seq}\\n+\\n{complete_f_qual}\"\n",
    "        r2 = f\"Test{i}\\n{complete_r_seq}\\n+\\n{complete_r_qual}\"\n",
    "        \n",
    "        return r1, r2\n",
    "    \n",
    "    def build_start_seq_f(self):\n",
    "        \"\"\"\n",
    "        Returns the sequence and qualities for the forward primer, adapter, barcode,\n",
    "        and frameshift as we would see them in a fastq file\n",
    "        \"\"\"\n",
    "        # Build the sequence\n",
    "        forward_seed_and_shift = \"\".join(self.refseq.primer_seed_f + \n",
    "                                         self.refseq.frameshift_bp_front)\n",
    "        forward_read_start = (self.f_barcode + ADAPTER_F + forward_seed_and_shift)\n",
    "\n",
    "        # Build qualities\n",
    "        quals = np.concatenate((\n",
    "            self.refseq.fbc_qualities,\n",
    "            self.refseq.adapter_qualities_f,\n",
    "            self.refseq.primer_qualities_f,\n",
    "            self.refseq.frameshift_front_qualities\n",
    "        ))\n",
    "        assert len(quals) == len(forward_read_start)\n",
    "        \n",
    "        return forward_read_start, ord_to_chr(quals)\n",
    "        \n",
    "    def build_start_seq_r(self):\n",
    "        \"\"\"\n",
    "        Returns the sequence and qualities for the reverse primer, adapter, barcode,\n",
    "        and frameshift as we would see them in a fastq file\n",
    "        \"\"\"\n",
    "        # Build the sequence\n",
    "        reverse_seed_and_shift = reverse_complement(\"\".join(self.refseq.frameshift_bp_back +\n",
    "                                                            self.refseq.primer_seed_r))\n",
    "        reverse_read_start = (self.r_barcode + ADAPTER_R + reverse_seed_and_shift)\n",
    "        \n",
    "        # Build qualities\n",
    "        quals = np.concatenate((\n",
    "            self.refseq.rbc_qualities,\n",
    "            self.refseq.adapter_qualities_r,\n",
    "            self.refseq.frameshift_back_qualities,\n",
    "            self.refseq.primer_qualities_r\n",
    "        ))\n",
    "        \n",
    "        assert len(quals) == len(reverse_read_start)\n",
    "        \n",
    "        return reverse_read_start, ord_to_chr(quals)\n",
    "    \n",
    "    def build_all_reads(self):\n",
    "        \"\"\"\n",
    "        Generates reads for a well.\n",
    "        \"\"\"\n",
    "        # Build lists for holding outputs\n",
    "        forward_reads = []\n",
    "        reverse_reads = []\n",
    "\n",
    "        # Build perfect reads\n",
    "        for variant in self.variants:\n",
    "            f_perfect, r_perfect = variant.build_perfect_reads()\n",
    "            forward_reads.extend(f_perfect)\n",
    "            reverse_reads.extend(r_perfect)\n",
    "\n",
    "        # Now augment with bad reads\n",
    "        for f_bad, r_bad in self.build_corrupted_reads():\n",
    "            forward_reads.extend(f_bad)\n",
    "            reverse_reads.extend(r_bad)\n",
    "        \n",
    "        return forward_reads, reverse_reads\n",
    "    \n",
    "    def build_output_counts(self):\n",
    "        \"\"\"\n",
    "        Builds output files for the different `OutputCounts`\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def murder_well(self):\n",
    "        \"\"\"\n",
    "        With some frequency, screws up the variants in a well to force a DEAD variant.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_maximum_reads_ind(total_reads_available, total_variants, minimum_reads_per_variant):\n",
    "        \n",
    "        # Get the upper bound of sampling maximum reads\n",
    "        return total_reads_available - ((total_variants - 1) * minimum_reads_per_variant) + 1\n",
    "    \n",
    "    @property\n",
    "    def base_refseq(self):\n",
    "        return \"\".join(self.refseq.codon_refseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c3e0b-3264-43f0-a0dd-09e078c0add8",
   "metadata": {},
   "source": [
    "All FakeWell instances are held within a FakeRun instance that assigns barcodes to the fake wells, handles fake input generation, and builds expected outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c7e3758-0bdf-4968-9a86-8506ed7bf485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that holds information for a test run\n",
    "class FakeRun(FakeData):\n",
    "    def __init__(self, detailed = True):\n",
    "        \"\"\"\n",
    "        fakewells: A list of fully prepared FakeWell objects.\n",
    "        detailed: Whether or not we are using a detailed refseq file. \n",
    "        \"\"\"\n",
    "        # Set a random configuration\n",
    "        self.config = Config(detailed = detailed)\n",
    "                \n",
    "        # Build wells\n",
    "        self.wells = [None] * len(INDEX_DF)\n",
    "        unique_plates_found = {}\n",
    "        refseq_counter = -1\n",
    "        for i, row in enumerate(INDEX_DF.itertuples()):\n",
    "            \n",
    "            # One path for detailed, increment the refseq counter\n",
    "            if detailed:\n",
    "                refseq_counter += 1\n",
    "            \n",
    "            # Otherwise, only increment the counter if it is for a new\n",
    "            # plate\n",
    "            elif row.IndexPlate not in unique_plates_found:\n",
    "                unique_plates_found.add(row.IndexPlate)\n",
    "                refseq_counter += 1\n",
    "        \n",
    "            # Create a new well\n",
    "            well = FakeWell(self.config,\n",
    "                            self.config.refseqs[refseq_counter])\n",
    "            \n",
    "            # Assign information to the well\n",
    "            well.platename = row.IndexPlate\n",
    "            well.wellname = row.Well\n",
    "            well.f_barcode = row.FBC\n",
    "            well.r_barcode = row.RBC\n",
    "            \n",
    "            # Record\n",
    "            self.wells[i] = well\n",
    "            \n",
    "    def build_input(self, saveloc):        \n",
    "        \n",
    "        warnings.warn(\"Add an NNN version of the refseq\")\n",
    "        \n",
    "        # Loop over all wells. Generate reads\n",
    "        forward_reads = []\n",
    "        reverse_reads = []\n",
    "        for well in self.wells:\n",
    "            \n",
    "            # Produce reads if this is not a dud\n",
    "            if not well.dud_well:\n",
    "                f_well_reads, r_well_reads = well.build_all_reads()\n",
    "                forward_reads.extend(f_well_reads)\n",
    "                reverse_reads.extend(r_well_reads)\n",
    "        \n",
    "        # Return the fastq files ready for processing\n",
    "        f_savename = os.path.join(saveloc, f\"testinput_R1_allreads.fastq\")\n",
    "        r_savename = os.path.join(saveloc, f\"testinput_R2_allreads.fastq\")\n",
    "        with open(f_savename, \"w\") as f:\n",
    "            f.write(\"\\n\".join(forward_reads))\n",
    "        with open(r_savename, \"w\") as f:\n",
    "            f.write(\"\\n\".join(reverse_reads))\n",
    "            \n",
    "        # Build reference sequence files\n",
    "        \n",
    "    def build_output_counts(self):\n",
    "        \"\"\"\n",
    "        Builds output files for the different `OutputCounts`\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e17e1fd2-8327-4d57-9e1d-f9e4d389d6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18162/616808641.py:30: UserWarning: You need to make sure that the amino acid returned is different from the existing one. Same goes for the nucleotides.\n",
      "  warnings.warn(\"You need to make sure that the amino acid returned is different\"\n",
      "/tmp/ipykernel_18162/2844603749.py:35: UserWarning: Add `murder` to list of functions\n",
      "  warnings.warn(\"Add `murder` to list of functions\")\n"
     ]
    }
   ],
   "source": [
    "test_run = FakeRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1e6cd3d-8a03-4659-8ab5-8b33cfaf15a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run.build_input(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937796fc-381e-4720-a0a7-13f0aa8cdcd8",
   "metadata": {},
   "source": [
    "To do:\n",
    "1. Output refseq\n",
    "2. Fix warnings\n",
    "3. Run a test\n",
    "4. Get output counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5252313b-105d-4caf-9edb-80f5a478a22c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
